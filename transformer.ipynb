{"cells":[{"cell_type":"markdown","metadata":{"id":"n7OWM4HbSFHk"},"source":["# 트랜스포머 기초"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PkNRlWGS6tNP"},"outputs":[],"source":["pip install tensorflow==2.12.0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GQ5C29Zm6wxr"},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xlG_wBrp80ow"},"outputs":[],"source":["class PositionalEncoding(tf.keras.layers.Layer):\n","  def __init__(self, position, d_model):\n","    super(PositionalEncoding, self).__init__()\n","    self.pos_encoding = self.positional_encoding(position, d_model)\n","\n","  def get_angles(self, position, i, d_model):\n","    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n","    return position * angles\n","\n","  def positional_encoding(self, position, d_model):\n","    angle_rads = self.get_angles(\n","        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n","        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n","        d_model=d_model)\n","\n","    # 배열의 짝수 인덱스(2i)에는 사인 함수 적용\n","    sines = tf.math.sin(angle_rads[:, 0::2])\n","\n","    # 배열의 홀수 인덱스(2i+1)에는 코사인 함수 적용\n","    cosines = tf.math.cos(angle_rads[:, 1::2])\n","\n","    angle_rads = np.zeros(angle_rads.shape)\n","    angle_rads[:, 0::2] = sines\n","    angle_rads[:, 1::2] = cosines\n","    pos_encoding = tf.constant(angle_rads)\n","    pos_encoding = pos_encoding[tf.newaxis, ...]\n","\n","    print(pos_encoding.shape)\n","    return tf.cast(pos_encoding, tf.float32)\n","\n","  def call(self, inputs):\n","    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Go2wP8Fk8s4_"},"outputs":[],"source":["def scaled_dot_product_attention(query, key, value, mask):\n","  # query 크기 : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n","  # key 크기 : (batch_size, num_heads, key의 문장 길이, d_model/num_heads)\n","  # value 크기 : (batch_size, num_heads, value의 문장 길이, d_model/num_heads)\n","  # padding_mask : (batch_size, 1, 1, key의 문장 길이)\n","\n","  # Q와 K의 곱. 어텐션 스코어 행렬.\n","  matmul_qk = tf.matmul(query, key, transpose_b=True)\n","\n","  # 스케일링\n","  # dk의 루트값으로 나눠준다.\n","  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n","  logits = matmul_qk / tf.math.sqrt(depth)\n","\n","  # 마스킹. 어텐션 스코어 행렬의 마스킹 할 위치에 매우 작은 음수값을 넣는다.\n","  # 매우 작은 값이므로 소프트맥스 함수를 지나면 행렬의 해당 위치의 값은 0이 된다.\n","  if mask is not None:\n","    logits += (mask * -1e9)\n","\n","  # 소프트맥스 함수는 마지막 차원인 key의 문장 길이 방향으로 수행된다.\n","  # attention weight : (batch_size, num_heads, query의 문장 길이, key의 문장 길이)\n","  attention_weights = tf.nn.softmax(logits, axis=-1)\n","\n","  # output : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n","  output = tf.matmul(attention_weights, value)\n","\n","  return output, attention_weights\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NoT3GV0Y9kHw"},"outputs":[],"source":["class MultiHeadAttention(tf.keras.layers.Layer):\n","\n","  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n","    super(MultiHeadAttention, self).__init__(name=name)\n","    self.num_heads = num_heads\n","    self.d_model = d_model\n","\n","    assert d_model % self.num_heads == 0\n","\n","    # d_model을 num_heads로 나눈 값.\n","    # 논문 기준 : 64\n","    self.depth = d_model // self.num_heads\n","\n","    # WQ, WK, WV에 해당하는 밀집층 정의\n","    self.query_dense = tf.keras.layers.Dense(units=d_model)\n","    self.key_dense = tf.keras.layers.Dense(units=d_model)\n","    self.value_dense = tf.keras.layers.Dense(units=d_model)\n","\n","    # WO에 해당하는 밀집층 정의\n","    self.dense = tf.keras.layers.Dense(units=d_model)\n","\n","  # num_heads 개수만큼 q, k, v를 split하는 함수\n","  def split_heads(self, inputs, batch_size):\n","    inputs = tf.reshape(\n","        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n","    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n","\n","  def call(self, inputs):\n","    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n","        'value'], inputs['mask']\n","    batch_size = tf.shape(query)[0]\n","\n","    # 1. WQ, WK, WV에 해당하는 밀집층 지나기\n","    # q : (batch_size, query의 문장 길이, d_model)\n","    # k : (batch_size, key의 문장 길이, d_model)\n","    # v : (batch_size, value의 문장 길이, d_model)\n","    # 참고) 인코더(k, v)-디코더(q) 어텐션에서는 query 길이와 key, value의 길이는 다를 수 있다.\n","    query = self.query_dense(query)\n","    key = self.key_dense(key)\n","    value = self.value_dense(value)\n","\n","    # 2. 헤드 나누기\n","    # q : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n","    # k : (batch_size, num_heads, key의 문장 길이, d_model/num_heads)\n","    # v : (batch_size, num_heads, value의 문장 길이, d_model/num_heads)\n","    query = self.split_heads(query, batch_size)\n","    key = self.split_heads(key, batch_size)\n","    value = self.split_heads(value, batch_size)\n","\n","    # 3. 스케일드 닷 프로덕트 어텐션. 앞서 구현한 함수 사용.\n","    # (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n","    scaled_attention, _ = scaled_dot_product_attention(query, key, value, mask)\n","    # (batch_size, query의 문장 길이, num_heads, d_model/num_heads)\n","    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n","\n","    # 4. 헤드 연결(concatenate)하기\n","    # (batch_size, query의 문장 길이, d_model)\n","    concat_attention = tf.reshape(scaled_attention,\n","                                  (batch_size, -1, self.d_model))\n","\n","    # 5. WO에 해당하는 밀집층 지나기\n","    # (batch_size, query의 문장 길이, d_model)\n","    outputs = self.dense(concat_attention)\n","\n","    return outputs\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-uQz4k_295RA"},"outputs":[],"source":["def create_padding_mask(x):\n","  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n","  # (batch_size, 1, 1, key의 문장 길이)\n","  return mask[:, tf.newaxis, tf.newaxis, :]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nyGk2k5ICUyQ"},"outputs":[],"source":["def encoder_layer(dff, d_model, num_heads, dropout, name=\"encoder_layer\"):\n","  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n","\n","  # 인코더는 패딩 마스크 사용\n","  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n","\n","  # 멀티-헤드 어텐션 (첫번째 서브층 / 셀프 어텐션)\n","  attention = MultiHeadAttention(\n","      d_model, num_heads, name=\"attention\")({\n","          'query': inputs, 'key': inputs, 'value': inputs, # Q = K = V\n","          'mask': padding_mask # 패딩 마스크 사용\n","      })\n","\n","  # 드롭아웃 + 잔차 연결과 층 정규화\n","  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n","  attention = tf.keras.layers.LayerNormalization(\n","      epsilon=1e-6)(inputs + attention)\n","\n","  # 포지션 와이즈 피드 포워드 신경망 (두번째 서브층)\n","  outputs = tf.keras.layers.Dense(units=dff, activation='relu')(attention)\n","  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n","\n","  # 드롭아웃 + 잔차 연결과 층 정규화\n","  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n","  outputs = tf.keras.layers.LayerNormalization(\n","      epsilon=1e-6)(attention + outputs)\n","\n","  return tf.keras.Model(\n","      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hGFjBpWbCsVg"},"outputs":[],"source":["def encoder(vocab_size, num_layers, dff,\n","            d_model, num_heads, dropout,\n","            name=\"encoder\"):\n","  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n","\n","  # 인코더는 패딩 마스크 사용\n","  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n","\n","  # 포지셔널 인코딩 + 드롭아웃\n","  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n","  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n","  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n","  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n","\n","  # 인코더를 num_layers개 쌓기\n","  for i in range(num_layers):\n","    outputs = encoder_layer(dff=dff, d_model=d_model, num_heads=num_heads,\n","        dropout=dropout, name=\"encoder_layer_{}\".format(i),\n","    )([outputs, padding_mask])\n","\n","  return tf.keras.Model(\n","      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4azNNC5vCvDU"},"outputs":[],"source":["# 디코더의 첫번째 서브층(sublayer)에서 미래 토큰을 Mask하는 함수\n","def create_look_ahead_mask(x):\n","  seq_len = tf.shape(x)[1]\n","  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n","  padding_mask = create_padding_mask(x) # 패딩 마스크도 포함\n","  return tf.maximum(look_ahead_mask, padding_mask)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hrgAwjbdC11l"},"outputs":[],"source":["def decoder_layer(dff, d_model, num_heads, dropout, name=\"decoder_layer\"):\n","  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n","  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n","\n","  # 룩어헤드 마스크(첫번째 서브층)\n","  look_ahead_mask = tf.keras.Input(\n","      shape=(1, None, None), name=\"look_ahead_mask\")\n","\n","  # 패딩 마스크(두번째 서브층)\n","  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n","\n","  # 멀티-헤드 어텐션 (첫번째 서브층 / 마스크드 셀프 어텐션)\n","  attention1 = MultiHeadAttention(\n","      d_model, num_heads, name=\"attention_1\")(inputs={\n","          'query': inputs, 'key': inputs, 'value': inputs, # Q = K = V\n","          'mask': look_ahead_mask # 룩어헤드 마스크\n","      })\n","\n","  # 잔차 연결과 층 정규화\n","  attention1 = tf.keras.layers.LayerNormalization(\n","      epsilon=1e-6)(attention1 + inputs)\n","\n","  # 멀티-헤드 어텐션 (두번째 서브층 / 디코더-인코더 어텐션)\n","  attention2 = MultiHeadAttention(\n","      d_model, num_heads, name=\"attention_2\")(inputs={\n","          'query': attention1, 'key': enc_outputs, 'value': enc_outputs, # Q != K = V\n","          'mask': padding_mask # 패딩 마스크\n","      })\n","\n","  # 드롭아웃 + 잔차 연결과 층 정규화\n","  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n","  attention2 = tf.keras.layers.LayerNormalization(\n","      epsilon=1e-6)(attention2 + attention1)\n","\n","  # 포지션 와이즈 피드 포워드 신경망 (세번째 서브층)\n","  outputs = tf.keras.layers.Dense(units=dff, activation='relu')(attention2)\n","  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n","\n","  # 드롭아웃 + 잔차 연결과 층 정규화\n","  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n","  outputs = tf.keras.layers.LayerNormalization(\n","      epsilon=1e-6)(outputs + attention2)\n","\n","  return tf.keras.Model(\n","      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n","      outputs=outputs,\n","      name=name)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YOC0TUP-Cwt5"},"outputs":[],"source":["def decoder(vocab_size, num_layers, dff,\n","            d_model, num_heads, dropout,\n","            name='decoder'):\n","  inputs = tf.keras.Input(shape=(None,), name='inputs')\n","  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n","\n","  # 디코더는 룩어헤드 마스크(첫번째 서브층)와 패딩 마스크(두번째 서브층) 둘 다 사용.\n","  look_ahead_mask = tf.keras.Input(\n","      shape=(1, None, None), name='look_ahead_mask')\n","  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n","\n","  # 포지셔널 인코딩 + 드롭아웃\n","  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n","  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n","  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n","  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n","\n","  # 디코더를 num_layers개 쌓기\n","  for i in range(num_layers):\n","    outputs = decoder_layer(dff=dff, d_model=d_model, num_heads=num_heads,\n","        dropout=dropout, name='decoder_layer_{}'.format(i),\n","    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n","\n","  return tf.keras.Model(\n","      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n","      outputs=outputs,\n","      name=name)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"na7wwOueC-y_"},"outputs":[],"source":["def transformer(vocab_size, num_layers, dff,\n","                d_model, num_heads, dropout,\n","                name=\"transformer\"):\n","\n","  # 인코더의 입력\n","  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n","\n","  # 디코더의 입력\n","  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n","\n","  # 인코더의 패딩 마스크\n","  enc_padding_mask = tf.keras.layers.Lambda(\n","      create_padding_mask, output_shape=(1, 1, None),\n","      name='enc_padding_mask')(inputs)\n","\n","  # 디코더의 룩어헤드 마스크(첫번째 서브층)\n","  look_ahead_mask = tf.keras.layers.Lambda(\n","      create_look_ahead_mask, output_shape=(1, None, None),\n","      name='look_ahead_mask')(dec_inputs)\n","\n","  # 디코더의 패딩 마스크(두번째 서브층)\n","  dec_padding_mask = tf.keras.layers.Lambda(\n","      create_padding_mask, output_shape=(1, 1, None),\n","      name='dec_padding_mask')(inputs)\n","\n","  # 인코더의 출력은 enc_outputs. 디코더로 전달된다.\n","  enc_outputs = encoder(vocab_size=vocab_size, num_layers=num_layers, dff=dff,\n","      d_model=d_model, num_heads=num_heads, dropout=dropout,\n","  )(inputs=[inputs, enc_padding_mask]) # 인코더의 입력은 입력 문장과 패딩 마스크\n","\n","  # 디코더의 출력은 dec_outputs. 출력층으로 전달된다.\n","  dec_outputs = decoder(vocab_size=vocab_size, num_layers=num_layers, dff=dff,\n","      d_model=d_model, num_heads=num_heads, dropout=dropout,\n","  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n","\n","  # 다음 단어 예측을 위한 출력층\n","  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n","\n","  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qlo5g1TRDuVm"},"outputs":[],"source":["def loss_function(y_true, y_pred):\n","  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n","\n","  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n","      from_logits=True, reduction='none')(y_true, y_pred)\n","\n","  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n","  loss = tf.multiply(loss, mask)\n","\n","  return tf.reduce_mean(loss)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gFr7LD5r_a9d"},"outputs":[],"source":["class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n","\n","  def __init__(self, d_model, warmup_steps=4000):\n","    super(CustomSchedule, self).__init__()\n","    self.d_model = d_model\n","    self.d_model = tf.cast(self.d_model, tf.float32)\n","    self.warmup_steps = warmup_steps\n","\n","  def __call__(self, step):\n","    step = tf.cast(step, tf.float32)\n","    arg1 = tf.math.rsqrt(step)\n","    arg2 = step * (self.warmup_steps**-1.5)\n","\n","    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n"]},{"cell_type":"markdown","metadata":{"id":"Bhshdc0QMPXw"},"source":["# 학습"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"58smUAgI_eJz"},"outputs":[],"source":["import pandas as pd\n","import re\n","import sentencepiece as spm"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":293},"executionInfo":{"elapsed":7480,"status":"ok","timestamp":1744167245588,"user":{"displayName":"최지원","userId":"07521749308437052461"},"user_tz":-540},"id":"gLe6HbFXRi7g","outputId":"ff31c36d-e30f-4aff-9811-8d94fe95779c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                        question  \\\n","0       엄마, 아기가 태어나니까 내가 부모로서 해야 할 게 참 많은 것 같아요.   \n","1                   그렇지? 아기 키우는 게 여간 어려운 일이 아니야.   \n","2  어제 평소보다도 격하게 막 온몸을 써가면서 울더라고요. 얼마나 당황했는지 몰라요.   \n","3        배가 고파서 그랬던 것 아닐까? 아기들은 배가 고프면 몸부림을 친단다.   \n","4       맞아요. 젖을 물려주니 금세 뚝 그쳤어요. 난 분명히 순했을 것 같은데.   \n","\n","                                          answer  \n","0                   그렇지? 아기 키우는 게 여간 어려운 일이 아니야.  \n","1  어제 평소보다도 격하게 막 온몸을 써가면서 울더라고요. 얼마나 당황했는지 몰라요.  \n","2        배가 고파서 그랬던 것 아닐까? 아기들은 배가 고프면 몸부림을 친단다.  \n","3       맞아요. 젖을 물려주니 금세 뚝 그쳤어요. 난 분명히 순했을 것 같은데.  \n","4      말도 마. 네가 얼마나 까탈스러웠는데. 우리 손주가 내 딸을 빼다 박았네.  "],"text/html":["\n","  <div id=\"df-9cb2f182-e7cc-4bbb-bbb6-cb8ab046d257\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>question</th>\n","      <th>answer</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>엄마, 아기가 태어나니까 내가 부모로서 해야 할 게 참 많은 것 같아요.</td>\n","      <td>그렇지? 아기 키우는 게 여간 어려운 일이 아니야.</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>그렇지? 아기 키우는 게 여간 어려운 일이 아니야.</td>\n","      <td>어제 평소보다도 격하게 막 온몸을 써가면서 울더라고요. 얼마나 당황했는지 몰라요.</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>어제 평소보다도 격하게 막 온몸을 써가면서 울더라고요. 얼마나 당황했는지 몰라요.</td>\n","      <td>배가 고파서 그랬던 것 아닐까? 아기들은 배가 고프면 몸부림을 친단다.</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>배가 고파서 그랬던 것 아닐까? 아기들은 배가 고프면 몸부림을 친단다.</td>\n","      <td>맞아요. 젖을 물려주니 금세 뚝 그쳤어요. 난 분명히 순했을 것 같은데.</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>맞아요. 젖을 물려주니 금세 뚝 그쳤어요. 난 분명히 순했을 것 같은데.</td>\n","      <td>말도 마. 네가 얼마나 까탈스러웠는데. 우리 손주가 내 딸을 빼다 박았네.</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9cb2f182-e7cc-4bbb-bbb6-cb8ab046d257')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-9cb2f182-e7cc-4bbb-bbb6-cb8ab046d257 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-9cb2f182-e7cc-4bbb-bbb6-cb8ab046d257');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-aad04ea2-196c-4ae8-a3af-37bc0ba5cb4f\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-aad04ea2-196c-4ae8-a3af-37bc0ba5cb4f')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-aad04ea2-196c-4ae8-a3af-37bc0ba5cb4f button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"train_data"}},"metadata":{},"execution_count":4}],"source":["train_data =  pd.read_csv('sympathy_qna.csv')\n","train_data.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-YsCwoYxL7zQ"},"outputs":[],"source":["questions = []\n","answers = []\n","for i in range(len(train_data)):\n","    # 구두점에 대해서 띄어쓰기\n","    # ex) 12시 땡! -> 12시 땡 !\n","    try:\n","      sentence = re.sub(r\"([?.!,])\", r\" \\1 \", train_data['question'][i])\n","      sentence = sentence.strip()\n","      sentence_a = re.sub(r\"([?.!,])\", r\" \\1 \", train_data['answer'][i])\n","      sentence_a = sentence_a.strip()\n","      questions.append(sentence)\n","      answers.append(sentence_a)\n","    except:\n","      #print(sentence)\n","      continue\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28,"status":"ok","timestamp":1744163823749,"user":{"displayName":"최지원","userId":"07521749308437052461"},"user_tz":-540},"id":"IgEG5EEFMIMG","outputId":"f69ffab5-412a-4a87-9ac6-7a64a3d8973a"},"outputs":[{"output_type":"stream","name":"stdout","text":["엄마 ,  아기가 태어나니까 내가 부모로서 해야 할 게 참 많은 것 같아요 .\n","그렇지 ?  아기 키우는 게 여간 어려운 일이 아니야 .\n","396729\n"]}],"source":["print(questions[0])\n","print(answers[0])\n","print(len(questions))"]},{"cell_type":"code","source":["f = open('s_data.txt', 'w')\n","for s in questions:\n","  f.write(s+'\\n')\n","for s in answers:\n","  f.write(s+'\\n')\n","f.close()"],"metadata":{"id":"c_wBEuhSR8zJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34,"status":"ok","timestamp":1744165064563,"user":{"displayName":"최지원","userId":"07521749308437052461"},"user_tz":-540},"id":"4EwqGDoBcjNy","outputId":"cc03be97-e4fc-49b8-dd91-896ccb95f18b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":28}],"source":["#학습\n","spm.SentencePieceTrainer.Train('--input=s_data.txt --model_prefix=s_vocab_20000 --vocab_size=20000 --model_type=bpe --max_sentence_length=9999')\n","#불러오기\n","tokenizer = spm.SentencePieceProcessor()\n","vocab_file = \"s_vocab_20000.model\"\n","tokenizer.load(vocab_file)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"scQPuet0MNsq"},"outputs":[],"source":["# 시작 토큰과 종료 토큰에 대한 정수 부여.\n","vocab_size = 20000\n","START_TOKEN, END_TOKEN = [vocab_size], [vocab_size + 1]\n","\n","# 시작 토큰과 종료 토큰을 고려하여 단어 집합의 크기를 + 2\n","VOCAB_SIZE = vocab_size + 2\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1744165095693,"user":{"displayName":"최지원","userId":"07521749308437052461"},"user_tz":-540},"id":"Bt-wtuaqMWck","outputId":"2072527f-b799-4796-a6e0-af83ee95e27c"},"outputs":[{"output_type":"stream","name":"stdout","text":["임의의 질문 샘플을 정수 인코딩 : [12892, 3, 1044, 2206, 5362, 980, 5785, 275, 775, 3, 3075, 6125, 6717, 518, 7508, 18896, 100]\n"]}],"source":["# 서브워드텍스트인코더 토크나이저의 .encode()를 사용하여 텍스트 시퀀스를 정수 시퀀스로 변환.\n","print('임의의 질문 샘플을 정수 인코딩 : {}'.format(tokenizer.encode(questions[70])))\n"]},{"cell_type":"code","source":["# 최대 길이를 40으로 정의\n","MAX_LENGTH = 40\n","\n","# 토큰화 / 정수 인코딩 / 시작 토큰과 종료 토큰 추가 / 패딩\n","def tokenize_and_filter(inputs, outputs):\n","  tokenized_inputs, tokenized_outputs = [], []\n","\n","  for (sentence1, sentence2) in zip(inputs, outputs):\n","    # encode(토큰화 + 정수 인코딩), 시작 토큰과 종료 토큰 추가\n","    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n","    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n","\n","    tokenized_inputs.append(sentence1)\n","    tokenized_outputs.append(sentence2)\n","\n","  # 패딩\n","  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n","      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n","  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n","      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n","\n","  return tokenized_inputs, tokenized_outputs\n"],"metadata":{"id":"alMsnBOqWHyu"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rX4Z0V5sMo0C"},"outputs":[],"source":["q, a = tokenize_and_filter(questions, answers)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":51,"status":"ok","timestamp":1744165244727,"user":{"displayName":"최지원","userId":"07521749308437052461"},"user_tz":-540},"id":"MFUGviNjMy9X","outputId":"085aa955-7167-40cf-cd5a-ba8d884e748d"},"outputs":[{"output_type":"stream","name":"stdout","text":["질문 데이터의 크기(shape) : (396729, 40)\n","답변 데이터의 크기(shape) : (396729, 40)\n"]}],"source":["print('질문 데이터의 크기(shape) :', q.shape)\n","print('답변 데이터의 크기(shape) :', a.shape)"]},{"cell_type":"code","source":["q[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"StoZ0PR-Wauj","executionInfo":{"status":"ok","timestamp":1744165255500,"user_tz":-540,"elapsed":25,"user":{"displayName":"최지원","userId":"07521749308437052461"}},"outputId":"630f5f2d-955c-4468-9c72-302dde641aee"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([20000,   105,     9,  5212,  5143,    45,    59,  7028,   416,\n","         110,    72,   195,   471,    14,   178,     3, 20001,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0], dtype=int32)"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":["a[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ugxuPoXQ-ncK","executionInfo":{"status":"ok","timestamp":1744165256298,"user_tz":-540,"elapsed":21,"user":{"displayName":"최지원","userId":"07521749308437052461"}},"outputId":"c7024140-87cc-4fb0-9995-f1119150895d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([20000,   806,    29,  2541,  3497,    72,  7926,  1020,   103,\n","         711,     3, 20001,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0,     0,     0,     0,     0,     0,\n","           0,     0,     0,     0], dtype=int32)"]},"metadata":{},"execution_count":36}]},{"cell_type":"code","source":["count = 0\n","for l in q:\n","  if l[-1] != 0 and l[-1] != 3 and l[-1] != 20001:\n","    count += 1\n","print(count)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tJqPy-XPO5xe","executionInfo":{"status":"ok","timestamp":1744165727734,"user_tz":-540,"elapsed":920,"user":{"displayName":"최지원","userId":"07521749308437052461"}},"outputId":"88176f34-9478-4b33-ab55-37ae9548a42c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0\n"]}]},{"cell_type":"code","source":["count = 0\n","for l in a:\n","  if l[-1] != 0 and l[-1] != 3 and l[-1] != 20001:\n","    count += 1\n","print(count)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N4a_F_dgOcfM","executionInfo":{"status":"ok","timestamp":1744165711740,"user_tz":-540,"elapsed":2120,"user":{"displayName":"최지원","userId":"07521749308437052461"}},"outputId":"337c167d-5fc9-40d3-c9cd-3608b4f1d81d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yFT09TepM0t9"},"outputs":[],"source":["# 텐서플로우 dataset을 이용하여 셔플(shuffle)을 수행하되, 배치 크기로 데이터를 묶는다.\n","# 또한 이 과정에서 교사 강요(teacher forcing)을 사용하기 위해서 디코더의 입력과 실제값 시퀀스를 구성한다.\n","BATCH_SIZE = 64\n","BUFFER_SIZE = 20000\n","\n","# 디코더의 실제값 시퀀스에서는 시작 토큰을 제거해야 한다.\n","dataset = tf.data.Dataset.from_tensor_slices((\n","    {\n","        'inputs': q,\n","        'dec_inputs': a[:, :-1] # 디코더의 입력. 마지막 패딩 토큰이 제거된다.\n","    },\n","    {\n","        'outputs': a[:, 1:]  # 맨 처음 토큰이 제거된다. 다시 말해 시작 토큰이 제거된다.\n","    },\n","))\n","\n","dataset = dataset.cache()\n","dataset = dataset.shuffle(BUFFER_SIZE)\n","dataset = dataset.batch(BATCH_SIZE)\n","dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10225,"status":"ok","timestamp":1744165772704,"user":{"displayName":"최지원","userId":"07521749308437052461"},"user_tz":-540},"id":"y7H4c-znM8F2","outputId":"641ae14b-3736-4c0f-a94a-5ccc98989040"},"outputs":[{"output_type":"stream","name":"stdout","text":["(1, 20002, 256)\n","(1, 20002, 256)\n"]}],"source":["tf.keras.backend.clear_session()\n","\n","# 하이퍼파라미터\n","D_MODEL = 256\n","NUM_LAYERS = 2\n","NUM_HEADS = 8\n","DFF = 512\n","DROPOUT = 0.1\n","\n","model = transformer(\n","    vocab_size=VOCAB_SIZE,\n","    num_layers=NUM_LAYERS,\n","    dff=DFF,\n","    d_model=D_MODEL,\n","    num_heads=NUM_HEADS,\n","    dropout=DROPOUT)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"znM6yx05M-ez"},"outputs":[],"source":["learning_rate = CustomSchedule(D_MODEL)\n","\n","optimizer = tf.keras.optimizers.Adam(\n","    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n","\n","def accuracy(y_true, y_pred):\n","  # 레이블의 크기는 (batch_size, MAX_LENGTH - 1)\n","  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n","  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n","\n","model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y0EeZQD257N_"},"outputs":[],"source":["EPOCHS = 20\n","path = 'sym_sentP_20000_cp-{epoch:03d}.ckpt'\n","\n","#1개 epoch가 끝날 때마다 저장\n","cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=path,\n","                                                 save_weights_only=True, verbose=1, save_freq=\"epoch\")\n","\n","model.fit(dataset, epochs=EPOCHS, callbacks=[cp_callback])"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}